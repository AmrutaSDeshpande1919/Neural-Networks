{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad20ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ad4e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine=pd.read_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\ExcelR\\\\Assignment\\\\Assignment 18 Neural Networks\\\\gas_turbines.csv\")\n",
    "turbine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4eb416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e8188b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      float64\n",
       "AP      float64\n",
       "AH      float64\n",
       "AFDP    float64\n",
       "GTEP    float64\n",
       "TIT     float64\n",
       "TAT     float64\n",
       "TEY     float64\n",
       "CDP     float64\n",
       "CO      float64\n",
       "NOX     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e4a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decd1d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.18846399361655"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we have to convert the TEY column into categorical column so need to calculate the mean first and then using lambda function categorize that column into 0's and 1's according to the mean\n",
    "turbine_mean = turbine.TEY.mean()\n",
    "turbine_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f8c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine['performance'] = turbine.TEY.map(lambda x: 1 if x > 134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c28e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8484\n",
       "1    6555\n",
       "Name: performance, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.performance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136cc249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  performance  \n",
       "0      3.1547  82.722            0  \n",
       "1      3.2363  82.776            0  \n",
       "2      3.2012  82.468            0  \n",
       "3      3.1923  82.670            0  \n",
       "4      3.2484  82.311            0  \n",
       "...       ...     ...          ...  \n",
       "15034  4.5186  79.559            0  \n",
       "15035  4.8470  79.917            0  \n",
       "15036  7.9632  90.912            0  \n",
       "15037  6.2494  93.227            0  \n",
       "15038  4.9816  92.498            0  \n",
       "\n",
       "[15039 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ad3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine.drop(['TEY'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c00cbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  performance  \n",
       "0      82.722            0  \n",
       "1      82.776            0  \n",
       "2      82.468            0  \n",
       "3      82.670            0  \n",
       "4      82.311            0  \n",
       "...       ...          ...  \n",
       "15034  79.559            0  \n",
       "15035  79.917            0  \n",
       "15036  90.912            0  \n",
       "15037  93.227            0  \n",
       "15038  92.498            0  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2908edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab251aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into x and y as input and output\n",
    "\n",
    "X = turbine.iloc[:,0:10]\n",
    "Y = turbine.iloc[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc38883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca0e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "15034    0\n",
       "15035    0\n",
       "15036    0\n",
       "15037    0\n",
       "15038    0\n",
       "Name: performance, Length: 15039, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf3ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152c6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8155a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f56ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08105957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e350557",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05bac4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143c175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train=mlp.predict(x_train)\n",
    "prediction_test = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78039099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e484584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e54485a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2422  118]\n",
      " [ 189 1783]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9445236059656122"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,prediction_test))\n",
    "np.mean(y_test==prediction_test)\n",
    "np.mean(y_train==prediction_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6179163",
   "metadata": {},
   "source": [
    "Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c32ae27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2733ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fb707b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc8cb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1008/1008 [==============================] - 4s 3ms/step - loss: 3.3858 - accuracy: 0.4254 - val_loss: 1.0429 - val_accuracy: 0.4483\n",
      "Epoch 2/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7804 - accuracy: 0.6495 - val_loss: 1.1340 - val_accuracy: 0.6377\n",
      "Epoch 3/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6358 - accuracy: 0.7224 - val_loss: 0.8332 - val_accuracy: 0.5211\n",
      "Epoch 4/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5937 - accuracy: 0.7386 - val_loss: 0.7236 - val_accuracy: 0.6198\n",
      "Epoch 5/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7563 - val_loss: 0.3278 - val_accuracy: 0.8513\n",
      "Epoch 6/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5088 - accuracy: 0.7632 - val_loss: 0.3256 - val_accuracy: 0.8312\n",
      "Epoch 7/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5182 - accuracy: 0.7639 - val_loss: 0.3287 - val_accuracy: 0.8007\n",
      "Epoch 8/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5158 - accuracy: 0.7674 - val_loss: 0.3323 - val_accuracy: 0.7860\n",
      "Epoch 9/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4876 - accuracy: 0.7751 - val_loss: 0.3406 - val_accuracy: 0.7657\n",
      "Epoch 10/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4930 - accuracy: 0.7746 - val_loss: 0.2822 - val_accuracy: 0.8584\n",
      "Epoch 11/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4763 - accuracy: 0.7761 - val_loss: 0.2743 - val_accuracy: 0.8767\n",
      "Epoch 12/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.7781 - val_loss: 0.2698 - val_accuracy: 0.8719\n",
      "Epoch 13/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4461 - accuracy: 0.7856 - val_loss: 0.2672 - val_accuracy: 0.8634\n",
      "Epoch 14/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4427 - accuracy: 0.7846 - val_loss: 0.3637 - val_accuracy: 0.8352\n",
      "Epoch 15/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.7852 - val_loss: 0.3562 - val_accuracy: 0.7459\n",
      "Epoch 16/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.7941 - val_loss: 0.4385 - val_accuracy: 0.8289\n",
      "Epoch 17/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.7892 - val_loss: 0.9551 - val_accuracy: 0.6883\n",
      "Epoch 18/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.7920 - val_loss: 0.4854 - val_accuracy: 0.8279\n",
      "Epoch 19/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.7910 - val_loss: 0.3001 - val_accuracy: 0.7854\n",
      "Epoch 20/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4173 - accuracy: 0.7948 - val_loss: 0.5406 - val_accuracy: 0.7223\n",
      "Epoch 21/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4148 - accuracy: 0.7925 - val_loss: 0.2542 - val_accuracy: 0.8555\n",
      "Epoch 22/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4068 - accuracy: 0.7940 - val_loss: 0.2466 - val_accuracy: 0.8781\n",
      "Epoch 23/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.7993 - val_loss: 0.2471 - val_accuracy: 0.9011\n",
      "Epoch 24/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4179 - accuracy: 0.7943 - val_loss: 0.2708 - val_accuracy: 0.8648\n",
      "Epoch 25/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3795 - accuracy: 0.8005 - val_loss: 0.2445 - val_accuracy: 0.8771\n",
      "Epoch 26/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8041 - val_loss: 0.2555 - val_accuracy: 0.8539\n",
      "Epoch 27/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3791 - accuracy: 0.8034 - val_loss: 0.3592 - val_accuracy: 0.8382\n",
      "Epoch 28/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3695 - accuracy: 0.8052 - val_loss: 0.2515 - val_accuracy: 0.9146\n",
      "Epoch 29/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3747 - accuracy: 0.8075 - val_loss: 0.2472 - val_accuracy: 0.8598\n",
      "Epoch 30/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8075 - val_loss: 0.2620 - val_accuracy: 0.8523\n",
      "Epoch 31/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3680 - accuracy: 0.8043 - val_loss: 0.2440 - val_accuracy: 0.8702\n",
      "Epoch 32/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3640 - accuracy: 0.8079 - val_loss: 0.2664 - val_accuracy: 0.8505\n",
      "Epoch 33/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3858 - accuracy: 0.8001 - val_loss: 0.3653 - val_accuracy: 0.8362\n",
      "Epoch 34/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8028 - val_loss: 0.2924 - val_accuracy: 0.8442\n",
      "Epoch 35/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3715 - accuracy: 0.8083 - val_loss: 0.2851 - val_accuracy: 0.8062\n",
      "Epoch 36/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.8085 - val_loss: 0.2669 - val_accuracy: 0.8505\n",
      "Epoch 37/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3323 - accuracy: 0.8199 - val_loss: 0.3298 - val_accuracy: 0.8390\n",
      "Epoch 38/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3542 - accuracy: 0.8093 - val_loss: 0.2615 - val_accuracy: 0.8946\n",
      "Epoch 39/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8102 - val_loss: 0.3154 - val_accuracy: 0.8414\n",
      "Epoch 40/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8178 - val_loss: 0.5971 - val_accuracy: 0.8134\n",
      "Epoch 41/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3477 - accuracy: 0.8110 - val_loss: 0.2431 - val_accuracy: 0.8827\n",
      "Epoch 42/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.8138 - val_loss: 0.3106 - val_accuracy: 0.8424\n",
      "Epoch 43/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3627 - accuracy: 0.8076 - val_loss: 0.2515 - val_accuracy: 0.8571\n",
      "Epoch 44/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8097 - val_loss: 0.2928 - val_accuracy: 0.8442\n",
      "Epoch 45/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8204 - val_loss: 0.2598 - val_accuracy: 0.8533\n",
      "Epoch 46/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3506 - accuracy: 0.8092 - val_loss: 0.4056 - val_accuracy: 0.8346\n",
      "Epoch 47/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.8135 - val_loss: 0.2550 - val_accuracy: 0.9134\n",
      "Epoch 48/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3387 - accuracy: 0.8187 - val_loss: 0.2448 - val_accuracy: 0.8668\n",
      "Epoch 49/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8173 - val_loss: 0.2461 - val_accuracy: 0.8612\n",
      "Epoch 50/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3459 - accuracy: 0.8106 - val_loss: 0.2650 - val_accuracy: 0.8505\n",
      "Epoch 51/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3392 - accuracy: 0.8101 - val_loss: 0.2713 - val_accuracy: 0.8481\n",
      "Epoch 52/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3519 - accuracy: 0.8090 - val_loss: 0.2557 - val_accuracy: 0.9162\n",
      "Epoch 53/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.8198 - val_loss: 0.2598 - val_accuracy: 0.9136\n",
      "Epoch 54/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8099 - val_loss: 0.3943 - val_accuracy: 0.7379\n",
      "Epoch 55/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3296 - accuracy: 0.8281 - val_loss: 0.2640 - val_accuracy: 0.8507\n",
      "Epoch 56/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8171 - val_loss: 0.2881 - val_accuracy: 0.8447\n",
      "Epoch 57/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3317 - accuracy: 0.8206 - val_loss: 0.2584 - val_accuracy: 0.8533\n",
      "Epoch 58/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3304 - accuracy: 0.8277 - val_loss: 0.2447 - val_accuracy: 0.9013\n",
      "Epoch 59/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3313 - accuracy: 0.8228 - val_loss: 0.2688 - val_accuracy: 0.8489\n",
      "Epoch 60/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3347 - accuracy: 0.8166 - val_loss: 0.2451 - val_accuracy: 0.8598\n",
      "Epoch 61/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3249 - accuracy: 0.8261 - val_loss: 0.2501 - val_accuracy: 0.9182\n",
      "Epoch 62/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3312 - accuracy: 0.8223 - val_loss: 0.2552 - val_accuracy: 0.9186\n",
      "Epoch 63/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3343 - accuracy: 0.8194 - val_loss: 0.3096 - val_accuracy: 0.8414\n",
      "Epoch 64/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3281 - accuracy: 0.8224 - val_loss: 0.2510 - val_accuracy: 0.8569\n",
      "Epoch 65/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3248 - accuracy: 0.8256 - val_loss: 0.2441 - val_accuracy: 0.9007\n",
      "Epoch 66/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3250 - accuracy: 0.8244 - val_loss: 0.3442 - val_accuracy: 0.7514\n",
      "Epoch 67/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3280 - accuracy: 0.8278 - val_loss: 0.2492 - val_accuracy: 0.9111\n",
      "Epoch 68/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3211 - accuracy: 0.8302 - val_loss: 0.2854 - val_accuracy: 0.8064\n",
      "Epoch 69/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3263 - accuracy: 0.8223 - val_loss: 0.2592 - val_accuracy: 0.8523\n",
      "Epoch 70/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3235 - accuracy: 0.8284 - val_loss: 0.2431 - val_accuracy: 0.8974\n",
      "Epoch 71/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3149 - accuracy: 0.8371 - val_loss: 0.2400 - val_accuracy: 0.8618\n",
      "Epoch 72/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3204 - accuracy: 0.8261 - val_loss: 0.2456 - val_accuracy: 0.8579\n",
      "Epoch 73/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8271 - val_loss: 0.2451 - val_accuracy: 0.8577\n",
      "Epoch 74/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3202 - accuracy: 0.8264 - val_loss: 0.4355 - val_accuracy: 0.8340\n",
      "Epoch 75/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8276 - val_loss: 0.2528 - val_accuracy: 0.8918\n",
      "Epoch 76/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3164 - accuracy: 0.8263 - val_loss: 0.2581 - val_accuracy: 0.8424\n",
      "Epoch 77/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3267 - accuracy: 0.8263 - val_loss: 0.2418 - val_accuracy: 0.8717\n",
      "Epoch 78/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3119 - accuracy: 0.8354 - val_loss: 0.3131 - val_accuracy: 0.8432\n",
      "Epoch 79/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3140 - accuracy: 0.8280 - val_loss: 0.2228 - val_accuracy: 0.8980\n",
      "Epoch 80/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3210 - accuracy: 0.8265 - val_loss: 0.2523 - val_accuracy: 0.9124\n",
      "Epoch 81/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8292 - val_loss: 0.2271 - val_accuracy: 0.9039\n",
      "Epoch 82/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8345 - val_loss: 0.2923 - val_accuracy: 0.7830\n",
      "Epoch 83/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8281 - val_loss: 0.2368 - val_accuracy: 0.8878\n",
      "Epoch 84/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8345 - val_loss: 0.2673 - val_accuracy: 0.8473\n",
      "Epoch 85/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3092 - accuracy: 0.8361 - val_loss: 0.3566 - val_accuracy: 0.8400\n",
      "Epoch 86/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8284 - val_loss: 0.2521 - val_accuracy: 0.8519\n",
      "Epoch 87/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3160 - accuracy: 0.8278 - val_loss: 0.2266 - val_accuracy: 0.8946\n",
      "Epoch 88/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8282 - val_loss: 0.2421 - val_accuracy: 0.8596\n",
      "Epoch 89/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3193 - accuracy: 0.8252 - val_loss: 0.2520 - val_accuracy: 0.8527\n",
      "Epoch 90/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3170 - accuracy: 0.8282 - val_loss: 0.2429 - val_accuracy: 0.8551\n",
      "Epoch 91/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.8349 - val_loss: 0.2581 - val_accuracy: 0.8497\n",
      "Epoch 92/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3175 - accuracy: 0.8308 - val_loss: 0.2351 - val_accuracy: 0.9085\n",
      "Epoch 93/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3183 - accuracy: 0.8332 - val_loss: 0.2692 - val_accuracy: 0.8449\n",
      "Epoch 94/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3247 - accuracy: 0.8260 - val_loss: 0.2760 - val_accuracy: 0.8463\n",
      "Epoch 95/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3204 - accuracy: 0.8321 - val_loss: 0.2680 - val_accuracy: 0.8608\n",
      "Epoch 96/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3199 - accuracy: 0.8316 - val_loss: 0.2353 - val_accuracy: 0.9047\n",
      "Epoch 97/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3218 - accuracy: 0.8261 - val_loss: 0.2419 - val_accuracy: 0.9045\n",
      "Epoch 98/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3185 - accuracy: 0.8314 - val_loss: 0.2629 - val_accuracy: 0.8479\n",
      "Epoch 99/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3227 - accuracy: 0.8259 - val_loss: 0.2399 - val_accuracy: 0.8827\n",
      "Epoch 100/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3222 - accuracy: 0.8264 - val_loss: 0.2593 - val_accuracy: 0.8759\n",
      "Epoch 101/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3166 - accuracy: 0.8285 - val_loss: 0.3092 - val_accuracy: 0.8396\n",
      "Epoch 102/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3195 - accuracy: 0.8280 - val_loss: 0.2395 - val_accuracy: 0.8658\n",
      "Epoch 103/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3114 - accuracy: 0.8307 - val_loss: 0.2491 - val_accuracy: 0.8507\n",
      "Epoch 104/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3255 - accuracy: 0.8257 - val_loss: 0.2629 - val_accuracy: 0.8475\n",
      "Epoch 105/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3192 - accuracy: 0.8319 - val_loss: 0.2429 - val_accuracy: 0.8654\n",
      "Epoch 106/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3133 - accuracy: 0.8279 - val_loss: 0.2798 - val_accuracy: 0.8467\n",
      "Epoch 107/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3117 - accuracy: 0.8322 - val_loss: 0.2393 - val_accuracy: 0.8575\n",
      "Epoch 108/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3091 - accuracy: 0.8335 - val_loss: 0.2365 - val_accuracy: 0.9200\n",
      "Epoch 109/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3117 - accuracy: 0.8338 - val_loss: 0.2593 - val_accuracy: 0.8501\n",
      "Epoch 110/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3214 - accuracy: 0.8289 - val_loss: 0.2505 - val_accuracy: 0.8527\n",
      "Epoch 111/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3182 - accuracy: 0.8257 - val_loss: 0.2423 - val_accuracy: 0.8582\n",
      "Epoch 112/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3173 - accuracy: 0.8301 - val_loss: 0.2421 - val_accuracy: 0.9053\n",
      "Epoch 113/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8291 - val_loss: 0.2927 - val_accuracy: 0.7780\n",
      "Epoch 114/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3212 - accuracy: 0.8290 - val_loss: 0.2440 - val_accuracy: 0.9097\n",
      "Epoch 115/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3158 - accuracy: 0.8327 - val_loss: 0.2546 - val_accuracy: 0.8882\n",
      "Epoch 116/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3149 - accuracy: 0.8275 - val_loss: 0.2419 - val_accuracy: 0.8563\n",
      "Epoch 117/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3239 - accuracy: 0.8226 - val_loss: 0.2819 - val_accuracy: 0.8438\n",
      "Epoch 118/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3330 - accuracy: 0.8218 - val_loss: 0.2960 - val_accuracy: 0.8398\n",
      "Epoch 119/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3189 - accuracy: 0.8268 - val_loss: 0.2438 - val_accuracy: 0.8559\n",
      "Epoch 120/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3155 - accuracy: 0.8279 - val_loss: 0.2579 - val_accuracy: 0.8991\n",
      "Epoch 121/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3256 - accuracy: 0.8236 - val_loss: 0.2863 - val_accuracy: 0.8430\n",
      "Epoch 122/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3171 - accuracy: 0.8312 - val_loss: 0.2743 - val_accuracy: 0.8265\n",
      "Epoch 123/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3107 - accuracy: 0.8353 - val_loss: 0.2475 - val_accuracy: 0.8535\n",
      "Epoch 124/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3085 - accuracy: 0.8355 - val_loss: 0.2429 - val_accuracy: 0.9128\n",
      "Epoch 125/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3104 - accuracy: 0.8333 - val_loss: 0.2473 - val_accuracy: 0.8545\n",
      "Epoch 126/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3138 - accuracy: 0.8354 - val_loss: 0.2509 - val_accuracy: 0.8533\n",
      "Epoch 127/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3105 - accuracy: 0.8363 - val_loss: 0.2738 - val_accuracy: 0.8475\n",
      "Epoch 128/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3154 - accuracy: 0.8345 - val_loss: 0.2363 - val_accuracy: 0.8866\n",
      "Epoch 129/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3262 - accuracy: 0.8255 - val_loss: 0.3085 - val_accuracy: 0.8336\n",
      "Epoch 130/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3260 - accuracy: 0.8264 - val_loss: 0.2321 - val_accuracy: 0.8636\n",
      "Epoch 131/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3189 - accuracy: 0.8233 - val_loss: 0.2499 - val_accuracy: 0.9015\n",
      "Epoch 132/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3126 - accuracy: 0.8337 - val_loss: 0.2372 - val_accuracy: 0.8634\n",
      "Epoch 133/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3133 - accuracy: 0.8294 - val_loss: 0.2428 - val_accuracy: 0.8602\n",
      "Epoch 134/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3161 - accuracy: 0.8357 - val_loss: 0.2411 - val_accuracy: 0.9158\n",
      "Epoch 135/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3142 - accuracy: 0.8303 - val_loss: 0.2509 - val_accuracy: 0.8535\n",
      "Epoch 136/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3096 - accuracy: 0.8310 - val_loss: 0.2284 - val_accuracy: 0.8916\n",
      "Epoch 137/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3126 - accuracy: 0.8312 - val_loss: 0.2357 - val_accuracy: 0.8719\n",
      "Epoch 138/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.8349 - val_loss: 0.2476 - val_accuracy: 0.8545\n",
      "Epoch 139/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3194 - accuracy: 0.8279 - val_loss: 0.2695 - val_accuracy: 0.8481\n",
      "Epoch 140/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3129 - accuracy: 0.8279 - val_loss: 0.2474 - val_accuracy: 0.8551\n",
      "Epoch 141/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8358 - val_loss: 0.2398 - val_accuracy: 0.8612\n",
      "Epoch 142/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3096 - accuracy: 0.8343 - val_loss: 0.2290 - val_accuracy: 0.9095\n",
      "Epoch 143/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3173 - accuracy: 0.8322 - val_loss: 0.2540 - val_accuracy: 0.8509\n",
      "Epoch 144/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3119 - accuracy: 0.8332 - val_loss: 0.2331 - val_accuracy: 0.8741\n",
      "Epoch 145/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3118 - accuracy: 0.8300 - val_loss: 0.2531 - val_accuracy: 0.8878\n",
      "Epoch 146/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3116 - accuracy: 0.8330 - val_loss: 0.2606 - val_accuracy: 0.8420\n",
      "Epoch 147/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3036 - accuracy: 0.8409 - val_loss: 0.2860 - val_accuracy: 0.7852\n",
      "Epoch 148/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3131 - accuracy: 0.8254 - val_loss: 0.2397 - val_accuracy: 0.8636\n",
      "Epoch 149/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3106 - accuracy: 0.8333 - val_loss: 0.2405 - val_accuracy: 0.8626\n",
      "Epoch 150/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3097 - accuracy: 0.8314 - val_loss: 0.2779 - val_accuracy: 0.8056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1867ac67cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e2490a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 1ms/step - loss: 0.3375 - accuracy: 0.7681\n",
      "accuracy: 76.81%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
